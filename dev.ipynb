{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zwimpee/1L-Sparse-Autoencoder/blob/main/dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Sparse Autoencoders, Feature Extraction, Dictionary Learning, Interpretability, and Supersymmetry* 🚀 😄"
      ],
      "metadata": {
        "id": "3rhxTT4SxyPB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "This notebook is to track progress on this personal project I am interested in, related to a peculiar similarity I think I may have noticed between 2 seemingly disparate worlds: $\\textbf{Deep Learning}$ and $\\textbf{Supersymmetry}$.\n",
        "\n",
        "In particular, I have noticed fairly recently (within the last ~1 month) that the work being done in interpretibility over the last 3 - 4 years, like what is being done at [Anthropic](https://www.anthropic.com/research), particularly the work being done by [Chris Olah](https://scholar.google.com/citations?user=6dskOSUAAAAJ&hl=en) on [Transformer Circuits](https://transformer-circuits.pub/) bears a striking similarity to the work [I have been a part of](https://arxiv.org/abs/1906.02971) as part of my experience with the research group out of Brown led by [Dr. Sylvester James Gates (Jim)](https://twitter.com/dr_jimgates).\n",
        "\n",
        "More specifically, I have caught on to a surprising thread (at least it is surprsising to me) that could suggest that the mathematics of supersymmetry and more generally quantum field theory could be applied directly to transformer-based neural networks (or perhaps neural networks in general) in order to both gain deeper insight into the mechanics of how a trained model is able to exhibit all of the emergent properties that we are observing as these models get larger, as well as to help more explicitly guide these models towards being truly aligned with human interests and priorities through some of the ablation/masking techniques studied in some of the works linked above.\n",
        "\n",
        "I will expand more deeply on this connection later in this document, but for now I think it is more imperative to get a better sense of what the current formalism looks like for this emerging field of *mechanistic interpretibility*, so let's get started..."
      ],
      "metadata": {
        "id": "SjBHiDo0TUMo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. `Setup`"
      ],
      "metadata": {
        "id": "x0WX6lN2guwg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 - `Setup` - Install Dependencies"
      ],
      "metadata": {
        "id": "Ao7MchHThtLH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qzU1eYv0SvAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5266596b-a4bf-4f59-99b3-6e931da90275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python3 -V"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformer_lens\n",
        "!pip install gradio\n",
        "# !pip install tiktoken\n",
        "# !pip install transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "lbFhN8dWTK_g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6dd757e-dd60-40c1-959d-7420711909e2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformer_lens\n",
            "  Downloading transformer_lens-1.17.0-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.1/137.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.23.0 (from transformer_lens)\n",
            "  Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beartype<0.15.0,>=0.14.1 (from transformer_lens)\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting better-abc<0.0.4,>=0.0.3 (from transformer_lens)\n",
            "  Downloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
            "Requirement already satisfied: datasets>=2.7.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.19.0)\n",
            "Collecting einops>=0.6.0 (from transformer_lens)\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fancy-einsum>=0.0.3 (from transformer_lens)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Collecting jaxtyping>=0.2.11 (from transformer_lens)\n",
            "  Downloading jaxtyping-0.2.28-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.0.3)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (13.7.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.1.99)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.66.2)\n",
            "Requirement already satisfied: transformers>=4.37.2 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.40.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.11.0)\n",
            "Collecting wandb>=0.13.5 (from transformer_lens)\n",
            "  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.13.4)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (2.31.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.9.5)\n",
            "Collecting typeguard==2.13.3 (from jaxtyping>=0.2.11->transformer_lens)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2024.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (2.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10->transformer_lens)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10->transformer_lens)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10->transformer_lens)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10->transformer_lens)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10->transformer_lens)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10->transformer_lens)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10->transformer_lens)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10->transformer_lens)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10->transformer_lens)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10->transformer_lens)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10->transformer_lens)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10->transformer_lens)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer_lens) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer_lens) (0.19.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb>=0.13.5->transformer_lens)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb>=0.13.5->transformer_lens)\n",
            "  Downloading sentry_sdk-2.0.1-py2.py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.8/266.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb>=0.13.5->transformer_lens)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb>=0.13.5->transformer_lens)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.16.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer_lens) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer_lens) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer_lens) (1.3.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: better-abc, typeguard, smmap, setproctitle, sentry-sdk, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fancy-einsum, einops, docker-pycreds, beartype, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jaxtyping, gitdb, nvidia-cusolver-cu12, GitPython, wandb, accelerate, transformer_lens\n",
            "Successfully installed GitPython-3.1.43 accelerate-0.29.3 beartype-0.14.1 better-abc-0.0.3 docker-pycreds-0.4.0 einops-0.8.0 fancy-einsum-0.0.3 gitdb-4.0.11 jaxtyping-0.2.28 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sentry-sdk-2.0.1 setproctitle-1.3.3 smmap-5.0.1 transformer_lens-1.17.0 typeguard-2.13.3 wandb-0.16.6\n",
            "Collecting gradio\n",
            "  Downloading gradio-4.28.3-py3-none-any.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.110.3-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.8/91.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.16.0 (from gradio)\n",
            "  Downloading gradio_client-0.16.0-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.4/314.4 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.22.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.1)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.4.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Collecting typer<1.0,>=0.12 (from gradio)\n",
            "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.11.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.16.0->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.16.0->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=fb06fb7cecd42f3873364cffd7f4a62da9e160dce7b45262305f288851c58caf\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, h11, aiofiles, uvicorn, starlette, httpcore, typer, httpx, fastapi, gradio-client, gradio\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 fastapi-0.110.3 ffmpy-0.3.2 gradio-4.28.3 gradio-client-0.16.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 orjson-3.10.2 pydub-0.25.1 python-multipart-0.0.9 ruff-0.4.2 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 typer-0.12.3 uvicorn-0.29.0 websockets-11.0.3\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.22.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 - `Setup` - Imports"
      ],
      "metadata": {
        "id": "l1T8XDeQT2QC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets\n",
        "import gradio as gr\n",
        "import json\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import pprint\n",
        "import pandas as pd\n",
        "# import tiktoken\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import transformer_lens\n",
        "\n",
        "from dataclasses import dataclass, field, fields\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import HfApi\n",
        "from IPython.display import HTML\n",
        "from functools import partial\n",
        "from transformers import GPT2TokenizerFast\n",
        "from tqdm.auto import tqdm\n",
        "from transformer_lens import (\n",
        "    # HookedTransformer,\n",
        "    utils\n",
        ")\n",
        "from typing import Any, Dict"
      ],
      "metadata": {
        "id": "dUf6nhkuTggs"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 `Setup` - Config definition and initialization"
      ],
      "metadata": {
        "id": "Bt40upYG7sjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class ModelConfig:\n",
        "    name: str\n",
        "    max_length: int\n",
        "    vocabulary_size: int\n",
        "    embed_dim: int\n",
        "    num_layers: int\n",
        "    num_heads: int\n",
        "    nonlinearity: nn.Module\n",
        "    dtype: torch.dtype\n",
        "\n",
        "@dataclass\n",
        "class DataConfig:\n",
        "    name: str\n",
        "    data: datasets.Dataset\n",
        "\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    num_steps: int\n",
        "    learning_rate: float\n",
        "    optimizer: Any\n",
        "    device: str\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    model: field(default=ModelConfig)\n",
        "    data: field(default_factory=DataConfig)\n",
        "    training: field(default_factory=TrainingConfig)\n",
        "\n",
        "\n",
        "\n",
        "# Model Configuration.\n",
        "model_name = \"openai-community/gpt2\"\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(model_name)\n",
        "max_length = 2**7  # 2**7 = 128\n",
        "vocab_size = len(tokenizer)  # <s>I think this is the GPT-2 vocab size, or close to it</s>\n",
        "embed_dim = max_length * 4  # Setting the embedding dimension to just be 4x the max length, seems like a relatively reasonable starting point, but I could be wrong...\n",
        "hidden_dim = 1028  # Can't remember if this is actually needed...\n",
        "num_layers = 2  # Trying to reproduce results from https://transformer-circuits.pub/2023/monosemantic-features/index.html\n",
        "block_size = 2**3  # 8\n",
        "num_heads = max_length % block_size  # I believe this will make it so each head (except the last one) computes the attention matrix across blocks of 8 tokens\n",
        "model_config_dict = {\n",
        "    \"name\": model_name,\n",
        "    \"tokenizer\": tokenizer,\n",
        "    \"max_length\": max_length,\n",
        "    \"vocabulary_size\": vocab_size,\n",
        "    \"embed_dim\": embed_dim,\n",
        "    \"num_layers\": num_layers,\n",
        "    \"num_heads\": num_heads,\n",
        "    \"nonlinearity\": nn.ReLU(),  # Will change this to gelu/other later.\n",
        "    \"dtype\": torch.bfloat16\n",
        "}\n",
        "\n",
        "model = ModelConfig(**model_config_dict)\n",
        "\n",
        "# - [X] TODO: Find dataset: https://huggingface.co/datasets\n",
        "# - [ ] TODO: Grab tiny shakespear dataset and process it for faster development iterations.\n",
        "# dataset_name = \"piqa\"\n",
        "dataset_name = \"Skylion007/openwebtext\"\n",
        "data = load_dataset(dataset_name, split=\"train\", trust_remote_code=True)\n",
        "\n",
        "\n",
        "\n",
        "# # data = load_dataset(\"NeelNanda/c4-code-20k\", split=\"train\")\n",
        "# tokenized_data = utils.tokenize_and_concatenate(data, tokenizer, max_length=512)\n",
        "# tokenized_data = tokenized_data.shuffle(42)\n",
        "# all_tokens = tokenized_data[\"tokens\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Configuration initialization.\n",
        "config = Config(\n",
        "    # - [X] TODO: Fill this out as much as possible at once during initialization!\n",
        "    model=model,\n",
        "    data=DataConfig(\n",
        "        **{\n",
        "            \"name\": dataset_name,\n",
        "            \"data\": data\n",
        "          }\n",
        "    )\n",
        "    training=TrainingConfig(\n",
        "        **{\n",
        "            \"batch_size\": 1,\n",
        "            \"num_steps\": 1000,\n",
        "            \"learning_rate\":1e-5\n",
        "          }\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "KAqaIhlF7sGM",
        "outputId": "1a78b4a8-6b9c-4ff7-d1e6-5f21a1157638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Config.__init__() missing 3 required positional arguments: 'model', 'data', and 'training'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-0738aeda0825>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m config = Config(\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;31m# - [ ] TODO: Fill this out as much as possible at once during initialization!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m )\n",
            "\u001b[0;31mTypeError\u001b[0m: Config.__init__() missing 3 required positional arguments: 'model', 'data', and 'training'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 - `Models` - Define the Models"
      ],
      "metadata": {
        "id": "y8ZmfyVBUWCa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 1.4.1 - Autoencoder"
      ],
      "metadata": {
        "id": "R3msnJbzT4Rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. - [ ] TODO: Reimplement my own AutoEncoder from scratch.\n",
        "...\n",
        "\n",
        "# 2. - [ ] TODO: Understand the autoencoder, both in terms of architecture as well as in terms of how we are trying to use it.\n",
        "#       This will be important in understanding the link between this aspect of MI and the mathematics that describes SUSY.\n",
        "# config = {\n",
        "#     \"seed\": 49,\n",
        "#     \"batch_size\": 4096,\n",
        "#     \"buffer_mult\": 384,\n",
        "#     \"lr\": 1e-4,\n",
        "#     \"num_tokens\": int(2e9),\n",
        "#     \"l1_coeff\": 3e-4,\n",
        "#     \"beta1\": 0.9,\n",
        "#     \"beta2\": 0.99,\n",
        "#     \"dict_mult\": 8,\n",
        "#     \"seq_len\": 128,\n",
        "#     \"d_mlp\": 2048,\n",
        "#     \"enc_dtype\":\"fp32\",\n",
        "#     \"remove_rare_dir\": False,\n",
        "# }\n",
        "# config[\"model_batch_size\"] = 64\n",
        "# config[\"buffer_size\"] = config[\"batch_size\"] * config[\"buffer_mult\"]\n",
        "# config[\"buffer_batches\"] = config[\"buffer_size\"] // config[\"seq_len\"]\n",
        "\n",
        "# DTYPES = {\"fp32\": torch.float32, \"fp16\": torch.float16, \"bf16\": torch.bfloat16}\n",
        "\n",
        "# class AutoEncoder(nn.Module):\n",
        "#     def __init__(self, config):\n",
        "#         super().__init__()\n",
        "#         d_hidden = config[\"d_mlp\"] * config[\"dict_mult\"]\n",
        "#         d_mlp = config[\"d_mlp\"]\n",
        "#         l1_coeff = config[\"l1_coeff\"]\n",
        "#         dtype = DTYPES[config[\"enc_dtype\"]]\n",
        "#         torch.manual_seed(config[\"seed\"])\n",
        "#         self.W_enc = nn.Parameter(torch.nn.init.kaiming_uniform_(torch.empty(d_mlp, d_hidden, dtype=dtype)))\n",
        "#         self.W_dec = nn.Parameter(torch.nn.init.kaiming_uniform_(torch.empty(d_hidden, d_mlp, dtype=dtype)))\n",
        "#         self.b_enc = nn.Parameter(torch.zeros(d_hidden, dtype=dtype))\n",
        "#         self.b_dec = nn.Parameter(torch.zeros(d_mlp, dtype=dtype))\n",
        "\n",
        "#         self.W_dec.data[:] = self.W_dec / self.W_dec.norm(dim=-1, keepdim=True)\n",
        "\n",
        "#         self.d_hidden = d_hidden\n",
        "#         self.l1_coeff = l1_coeff\n",
        "\n",
        "#         self.to(\"cuda\")\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x_cent = x - self.b_dec\n",
        "#         acts = F.relu(x_cent @ self.W_enc + self.b_enc)\n",
        "#         x_reconstruct = acts @ self.W_dec + self.b_dec\n",
        "#         l2_loss = (x_reconstruct.float() - x.float()).pow(2).sum(-1).mean(0)\n",
        "#         l1_loss = self.l1_coeff * (acts.float().abs().sum())\n",
        "#         loss = l2_loss + l1_loss\n",
        "#         return loss, x_reconstruct, acts, l2_loss, l1_loss\n",
        "\n",
        "#     @torch.no_grad()\n",
        "#     def remove_parallel_component_of_grads(self):\n",
        "#         W_dec_normed = self.W_dec / self.W_dec.norm(dim=-1, keepdim=True)\n",
        "#         W_dec_grad_proj = (self.W_dec.grad * W_dec_normed).sum(-1, keepdim=True) * W_dec_normed\n",
        "#         self.W_dec.grad -= W_dec_grad_proj\n",
        "\n",
        "#     # def get_version(self):\n",
        "#     #     return 1+max([int(file.name.split(\".\")[0]) for file in list(SAVE_DIR.iterdir()) if \"pt\" in str(file)])\n",
        "\n",
        "#     # def save(self):\n",
        "#     #     version = self.get_version()\n",
        "#     #     torch.save(self.state_dict(), SAVE_DIR/(str(version)+\".pt\"))\n",
        "#     #     with open(SAVE_DIR/(str(version)+\"_cfg.json\"), \"w\") as f:\n",
        "#     #         json.dump(cfg, f)\n",
        "#     #     print(\"Saved as version\", version)\n",
        "\n",
        "#     # def load(cls, version):\n",
        "#     #     cfg = (json.load(open(SAVE_DIR/(str(version)+\"_cfg.json\"), \"r\")))\n",
        "#     #     pprint.pprint(cfg)\n",
        "#     #     self = cls(cfg=cfg)\n",
        "#     #     self.load_state_dict(torch.load(SAVE_DIR/(str(version)+\".pt\")))\n",
        "#     #     return self\n",
        "\n",
        "#     @classmethod\n",
        "#     def load_from_hf(cls, version):\n",
        "#         \"\"\"\n",
        "#         Loads the saved autoencoder from HuggingFace.\n",
        "\n",
        "#         Version is expected to be an int, or \"run1\" or \"run2\"\n",
        "\n",
        "#         version 25 is the final checkpoint of the first autoencoder run,\n",
        "#         version 47 is the final checkpoint of the second autoencoder run.\n",
        "#         \"\"\"\n",
        "#         if version==\"run1\":\n",
        "#             version = 25\n",
        "#         elif version==\"run2\":\n",
        "#             version = 47\n",
        "\n",
        "#         cfg = utils.download_file_from_hf(\"NeelNanda/sparse_autoencoder\", f\"{version}_cfg.json\")\n",
        "#         pprint.pprint(cfg)\n",
        "#         self = cls(cfg=cfg)\n",
        "#         self.load_state_dict(utils.download_file_from_hf(\"ZacharyWimpee/sparse_autoencoder\", f\"{version}.pt\", force_is_torch=True))\n",
        "#         return self"
      ],
      "metadata": {
        "id": "S3ypesK0T67l"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4.2 - Transformer"
      ],
      "metadata": {
        "id": "zJUE_j_Tg0VE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODOs:\n",
        "# 1. - [X] TODO: Try and build the transformer from scratch without any help, as an exercise.\n",
        "# 2. - [ ] TODO: After getting as far as possible from memory, reference some examples to finish implementing the code below.\n",
        "\n",
        "###################################################################################\n",
        "\n",
        "# Attempt #1:\n",
        "# 1. - [X] TODO: Initialize the following classes:\n",
        "        # 1.1 - [X] TODO: Initialize the class for Attention\n",
        "        # 1.2 - [X] TODO: Initialize the class for MLP\n",
        "        # 1.3 - [X] TODO: Initialize MHSA\n",
        "        # 1.4 - [X] TODO: Initialize TransformerBlock(MHSA)\n",
        "        # 1.5 - [X] TODO: Initialize TransformerLanguageModel\n",
        "# 2. - [ ] TODO: DEBUG\n",
        "#---------------------------------------------------------------------------------#\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, config, **kwargs):\n",
        "        super().__init__()\n",
        "        ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        ...\n",
        "\n",
        "# - [X] TODO: 2. Implement the class for MLP\n",
        "# This one should be pretty easy, hopefully...\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, config, **kwargs):\n",
        "        super().__init__()\n",
        "        self.in_features = config.get(\"hidden_dim\", kwargs.get(\"hidden_dim\",hidden_dim))\n",
        "        self.out_features = config.get(\"hidden_dim\", kwargs.get(\"hidden_dim\",hidden_dim))\n",
        "        self.fc = nn.Linear(config.max_context, config.max_context)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "\n",
        "class MHSA(nn.Module):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "        ...\n",
        "\n",
        "    def forward(self, x):\n",
        "      ...\n",
        "\n",
        "class TransformerBlock(MHSA):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "        ...\n",
        "\n",
        "    def forward(self, x):\n",
        "        ...\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# - [X] TODO: Implement the class for Transformer.\n",
        "# - [X] TODO: Try and remember how to construct the rest of the transformer...\n",
        "# - [ ] TODO: Look at the docs and then try to finish up what we have so far...\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, config: ModelConfig|Dict, **kwargs):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Embedding(num_embeddings=config.vocabulary_size, embedding_dim=config.embed_dim),\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        ...\n",
        "\n",
        "    def generate(self, inp, **kwargs):\n",
        "        ...\n",
        "\n",
        "###################################################################################"
      ],
      "metadata": {
        "id": "p5kuP89Cg3Bw"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 - `Function Defs` - Utils\n"
      ],
      "metadata": {
        "id": "kju5GpaKVI80"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4.1 - `Function Defs` - \"Standard Lib\""
      ],
      "metadata": {
        "id": "copY5zhlgb8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `Function Def` - Train the Language Model"
      ],
      "metadata": {
        "id": "EHGizhCXAonF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# - [X] TODO: Implement training logic\n",
        "def train(model, tokenizer, data, config: TrainingConfig|None=None, **kwargs):\n",
        "    device = config.device or kwargs.get(\"device\", \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    train_data = data[:round(0.8*len(data))]\n",
        "    val_data = data[round(0.8*len(data)):round(0.9*len(data))]\n",
        "    test_data = data[round(0.9*len(data)):]\n",
        "\n",
        "    eval_every_n_batches = kwargs.get(\"eval_every_n_batches\", 1e4)\n",
        "    max_steps = kwargs.get(\"num_steps\", 1e5)\n",
        "\n",
        "    optimizer = kwargs.get(\"optimizer\")\n",
        "\n",
        "    loss_fn = kwargs.get(\"loss_fn\", F.binary_cross_entropy_with_logits)\n",
        "\n",
        "    for i in tqdm(range(len(train_data)), desc=\"Running training loop...\"):\n",
        "        model.train()\n",
        "        train_example = train_data[i]\n",
        "\n",
        "        model_input = tokenizer.encode(train_example[\"text\"], padding=\"max_length\", truncate=True, max_length=512, return_tensors=\"pt\").to(device)\n",
        "        model_output = model(**model_input)\n",
        "\n",
        "\n",
        "        if i % eval_every_n_batches == 0:\n",
        "            with torch.no_grad():\n",
        "                for j in tqdm(range(len(val_data)), desc=\"Running validation loop...\"):\n",
        "                    val_example = val_data[j]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        if i >= max_steps:\n",
        "          break\n",
        "\n",
        "      return test_data\n"
      ],
      "metadata": {
        "id": "lLKz3olJAtHW"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### `Function Def` - Evaluate the Language Model"
      ],
      "metadata": {
        "id": "GOd-KyMJ6-vK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, data):\n",
        "    ..."
      ],
      "metadata": {
        "id": "pGLnzmjb6_OG"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4.2 - `Function Defs` - Mechanistic Interpretibility"
      ],
      "metadata": {
        "id": "VfFLR5cnghBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.4.2.1 - `Function Defs` - Get Reconstruction Loss"
      ],
      "metadata": {
        "id": "3jR9xXgyVbih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replacement_hook(mlp_post, hook, encoder):\n",
        "    mlp_post_reconstr = encoder(mlp_post)[1]\n",
        "    return mlp_post_reconstr\n",
        "\n",
        "def mean_ablate_hook(mlp_post, hook):\n",
        "    mlp_post[:] = mlp_post.mean([0, 1])\n",
        "    return mlp_post\n",
        "\n",
        "def zero_ablate_hook(mlp_post, hook):\n",
        "    mlp_post[:] = 0.\n",
        "    return mlp_post\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_recons_loss(num_batches=5, local_encoder=None):\n",
        "    if local_encoder is None:\n",
        "        local_encoder = encoder\n",
        "    loss_list = []\n",
        "    for i in range(num_batches):\n",
        "        tokens = all_tokens[torch.randperm(len(all_tokens))[:cfg[\"model_batch_size\"]]]\n",
        "        loss = model(tokens, return_type=\"loss\")\n",
        "        recons_loss = model.run_with_hooks(tokens, return_type=\"loss\", fwd_hooks=[(utils.get_act_name(\"post\", 0), partial(replacement_hook, encoder=local_encoder))])\n",
        "        # mean_abl_loss = model.run_with_hooks(tokens, return_type=\"loss\", fwd_hooks=[(utils.get_act_name(\"post\", 0), mean_ablate_hook)])\n",
        "        zero_abl_loss = model.run_with_hooks(tokens, return_type=\"loss\", fwd_hooks=[(utils.get_act_name(\"post\", 0), zero_ablate_hook)])\n",
        "        loss_list.append((loss, recons_loss, zero_abl_loss))\n",
        "    losses = torch.tensor(loss_list)\n",
        "    loss, recons_loss, zero_abl_loss = losses.mean(0).tolist()\n",
        "\n",
        "    print(f\"loss: {loss:.4f}, recons_loss: {recons_loss:.4f}, zero_abl_loss: {zero_abl_loss:.4f}\")\n",
        "    score = ((zero_abl_loss - recons_loss)/(zero_abl_loss - loss))\n",
        "    print(f\"Reconstruction Score: {score:.2%}\")\n",
        "    # print(f\"{((zero_abl_loss - mean_abl_loss)/(zero_abl_loss - loss)).item():.2%}\")\n",
        "    return score, loss, recons_loss, zero_abl_loss"
      ],
      "metadata": {
        "id": "E-XN_do8VabW"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.4.2.2 - `Function Defs` - Get Frequencies"
      ],
      "metadata": {
        "id": "zxzbXJvLVhV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Frequency\n",
        "@torch.no_grad()\n",
        "def get_freqs(num_batches=25, local_encoder=None):\n",
        "    if local_encoder is None:\n",
        "        local_encoder = encoder\n",
        "    act_freq_scores = torch.zeros(local_encoder.d_hidden, dtype=torch.float32).cuda()\n",
        "    total = 0\n",
        "    for i in tqdm.trange(num_batches):\n",
        "        tokens = all_tokens[torch.randperm(len(all_tokens))[:autoencoder_config[\"model_batch_size\"]]]\n",
        "\n",
        "        _, cache = model.run_with_cache(tokens, stop_at_layer=1, names_filter=utils.get_act_name(\"post\", 0))\n",
        "        mlp_acts = cache[utils.get_act_name(\"post\", 0)]\n",
        "        mlp_acts = mlp_acts.reshape(-1, d_mlp)\n",
        "\n",
        "        hidden = local_encoder(mlp_acts)[2]\n",
        "\n",
        "        act_freq_scores += (hidden > 0).sum(0)\n",
        "        total+=hidden.shape[0]\n",
        "    act_freq_scores /= total\n",
        "    num_dead = (act_freq_scores==0).float().mean()\n",
        "    print(\"Num dead\", num_dead)\n",
        "    return act_freq_scores"
      ],
      "metadata": {
        "id": "y_UReEIDVjzo"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.4.2.3 - `Functions Defs` - Visualise Feature Utils"
      ],
      "metadata": {
        "id": "IAr8Tr8sVn-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from html import escape\n",
        "import colorsys\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "SPACE = \"·\"\n",
        "NEWLINE=\"↩\"\n",
        "TAB = \"→\"\n",
        "\n",
        "def create_html(strings, values, max_value=None, saturation=0.5, allow_different_length=False, return_string=False):\n",
        "    # escape strings to deal with tabs, newlines, etc.\n",
        "    escaped_strings = [escape(s, quote=True) for s in strings]\n",
        "    processed_strings = [\n",
        "        s.replace(\"\\n\", f\"{NEWLINE}<br/>\").replace(\"\\t\", f\"{TAB}&emsp;\").replace(\" \", \"&nbsp;\")\n",
        "        for s in escaped_strings\n",
        "    ]\n",
        "\n",
        "    if isinstance(values, torch.Tensor) and len(values.shape)>1:\n",
        "        values = values.flatten().tolist()\n",
        "\n",
        "    if not allow_different_length:\n",
        "        assert len(processed_strings) == len(values)\n",
        "\n",
        "    # scale values\n",
        "    if max_value is None:\n",
        "        max_value = max(max(values), -min(values))+1e-3\n",
        "    scaled_values = [v / max_value * saturation for v in values]\n",
        "\n",
        "    # create html\n",
        "    html = \"\"\n",
        "    for i, s in enumerate(processed_strings):\n",
        "        if i<len(scaled_values):\n",
        "            v = scaled_values[i]\n",
        "        else:\n",
        "            v = 0\n",
        "        if v < 0:\n",
        "            hue = 0  # hue for red in HSV\n",
        "        else:\n",
        "            hue = 0.66  # hue for blue in HSV\n",
        "        rgb_color = colorsys.hsv_to_rgb(\n",
        "            hue, v, 1\n",
        "        )  # hsv color with hue 0.66 (blue), saturation as v, value 1\n",
        "        hex_color = \"#%02x%02x%02x\" % (\n",
        "            int(rgb_color[0] * 255),\n",
        "            int(rgb_color[1] * 255),\n",
        "            int(rgb_color[2] * 255),\n",
        "        )\n",
        "        html += f'<span style=\"background-color: {hex_color}; border: 1px solid lightgray; font-size: 16px; border-radius: 3px;\">{s}</span>'\n",
        "    if return_string:\n",
        "        return html\n",
        "    else:\n",
        "        display(HTML(html))\n",
        "\n",
        "def basic_feature_vis(text, feature_index, max_val=0):\n",
        "    feature_in = encoder.W_enc[:, feature_index]\n",
        "    feature_bias = encoder.b_enc[feature_index]\n",
        "    _, cache = model.run_with_cache(text, stop_at_layer=1, names_filter=utils.get_act_name(\"post\", 0))\n",
        "    mlp_acts = cache[utils.get_act_name(\"post\", 0)][0]\n",
        "    feature_acts = F.relu((mlp_acts - encoder.b_dec) @ feature_in + feature_bias)\n",
        "    if max_val==0:\n",
        "        max_val = max(1e-7, feature_acts.max().item())\n",
        "        # print(max_val)\n",
        "    # if min_val==0:\n",
        "    #     min_val = min(-1e-7, feature_acts.min().item())\n",
        "    return basic_token_vis_make_str(text, feature_acts, max_val)\n",
        "def basic_token_vis_make_str(strings, values, max_val=None):\n",
        "    if not isinstance(strings, list):\n",
        "        strings = model.to_str_tokens(strings)\n",
        "    values = utils.to_numpy(values)\n",
        "    if max_val is None:\n",
        "        max_val = values.max()\n",
        "    # if min_val is None:\n",
        "    #     min_val = values.min()\n",
        "    header_string = f\"<h4>Max Range <b>{values.max():.4f}</b> Min Range: <b>{values.min():.4f}</b></h4>\"\n",
        "    header_string += f\"<h4>Set Max Range <b>{max_val:.4f}</b></h4>\"\n",
        "    # values[values>0] = values[values>0]/ma|x_val\n",
        "    # values[values<0] = values[values<0]/abs(min_val)\n",
        "    body_string = create_html(strings, values, max_value=max_val, return_string=True)\n",
        "    return header_string + body_string\n",
        "# display(HTML(basic_token_vis_make_str(tokens[0, :10], mlp_acts[0, :10, 7], 0.1)))\n",
        "# # %%\n",
        "# The `with gr.Blocks() as demo:` syntax just creates a variable called demo containing all these components\n",
        "import gradio as gr\n",
        "try:\n",
        "    demos[0].close()\n",
        "except:\n",
        "    pass\n",
        "demos = [None]\n",
        "def make_feature_vis_gradio(feature_id, starting_text=None, batch=None, pos=None):\n",
        "    if starting_text is None:\n",
        "        starting_text = model.to_string(all_tokens[batch, 1:pos+1])\n",
        "    try:\n",
        "        demos[0].close()\n",
        "    except:\n",
        "        pass\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.HTML(value=f\"Hacky Interactive Neuroscope for gelu-1l\")\n",
        "        # The input elements\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                text = gr.Textbox(label=\"Text\", value=starting_text)\n",
        "                # Precision=0 makes it an int, otherwise it's a float\n",
        "                # Value sets the initial default value\n",
        "                feature_index = gr.Number(\n",
        "                    label=\"Feature Index\", value=feature_id, precision=0\n",
        "                )\n",
        "                # # If empty, these two map to None\n",
        "                max_val = gr.Number(label=\"Max Value\", value=None)\n",
        "                # min_val = gr.Number(label=\"Min Value\", value=None)\n",
        "                inputs = [text, feature_index, max_val]\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                # The output element\n",
        "                out = gr.HTML(label=\"Neuron Acts\", value=basic_feature_vis(starting_text, feature_id))\n",
        "        for inp in inputs:\n",
        "            inp.change(basic_feature_vis, inputs, out)\n",
        "    demo.launch(share=True)\n",
        "    demos[0] = demo"
      ],
      "metadata": {
        "id": "k2Cb-XmrVqgl"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### `Function Def` - Inspecting Top Logits"
      ],
      "metadata": {
        "id": "O2UuRmEXVtBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SPACE = \"·\"\n",
        "NEWLINE=\"↩\"\n",
        "TAB = \"→\"\n",
        "def process_token(s):\n",
        "    if isinstance(s, torch.Tensor):\n",
        "        s = s.item()\n",
        "    if isinstance(s, np.int64):\n",
        "        s = s.item()\n",
        "    if isinstance(s, int):\n",
        "        s = model.to_string(s)\n",
        "    s = s.replace(\" \", SPACE)\n",
        "    s = s.replace(\"\\n\", NEWLINE+\"\\n\")\n",
        "    s = s.replace(\"\\t\", TAB)\n",
        "    return s\n",
        "\n",
        "def process_tokens(l):\n",
        "    if isinstance(l, str):\n",
        "        l = model.to_str_tokens(l)\n",
        "    elif isinstance(l, torch.Tensor) and len(l.shape)>1:\n",
        "        l = l.squeeze(0)\n",
        "    return [process_token(s) for s in l]\n",
        "\n",
        "def process_tokens_index(l):\n",
        "    if isinstance(l, str):\n",
        "        l = model.to_str_tokens(l)\n",
        "    elif isinstance(l, torch.Tensor) and len(l.shape)>1:\n",
        "        l = l.squeeze(0)\n",
        "    return [f\"{process_token(s)}/{i}\" for i,s in enumerate(l)]\n",
        "\n",
        "def create_vocab_df(logit_vec, make_probs=False, full_vocab=None):\n",
        "    if full_vocab is None:\n",
        "        full_vocab = process_tokens(model.to_str_tokens(torch.arange(model.cfg.d_vocab)))\n",
        "    vocab_df = pd.DataFrame({\"token\": full_vocab, \"logit\": utils.to_numpy(logit_vec)})\n",
        "    if make_probs:\n",
        "        vocab_df[\"log_prob\"] = utils.to_numpy(logit_vec.log_softmax(dim=-1))\n",
        "        vocab_df[\"prob\"] = utils.to_numpy(logit_vec.softmax(dim=-1))\n",
        "    return vocab_df.sort_values(\"logit\", ascending=False)"
      ],
      "metadata": {
        "id": "-SBs3A3PVury"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.4.2.4 - `Function Defs` - Make Token DataFrame"
      ],
      "metadata": {
        "id": "zaT9C-f4VxgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_flatten(nested_list):\n",
        "    return [x for y in nested_list for x in y]\n",
        "def make_token_df(tokens, len_prefix=5, len_suffix=1):\n",
        "    str_tokens = [process_tokens(model.to_str_tokens(t)) for t in tokens]\n",
        "    unique_token = [[f\"{s}/{i}\" for i, s in enumerate(str_tok)] for str_tok in str_tokens]\n",
        "\n",
        "    context = []\n",
        "    batch = []\n",
        "    pos = []\n",
        "    label = []\n",
        "    for b in range(tokens.shape[0]):\n",
        "        # context.append([])\n",
        "        # batch.append([])\n",
        "        # pos.append([])\n",
        "        # label.append([])\n",
        "        for p in range(tokens.shape[1]):\n",
        "            prefix = \"\".join(str_tokens[b][max(0, p-len_prefix):p])\n",
        "            if p==tokens.shape[1]-1:\n",
        "                suffix = \"\"\n",
        "            else:\n",
        "                suffix = \"\".join(str_tokens[b][p+1:min(tokens.shape[1]-1, p+1+len_suffix)])\n",
        "            current = str_tokens[b][p]\n",
        "            context.append(f\"{prefix}|{current}|{suffix}\")\n",
        "            batch.append(b)\n",
        "            pos.append(p)\n",
        "            label.append(f\"{b}/{p}\")\n",
        "    # print(len(batch), len(pos), len(context), len(label))\n",
        "    return pd.DataFrame(dict(\n",
        "        str_tokens=list_flatten(str_tokens),\n",
        "        unique_token=list_flatten(unique_token),\n",
        "        context=context,\n",
        "        batch=batch,\n",
        "        pos=pos,\n",
        "        label=label,\n",
        "    ))"
      ],
      "metadata": {
        "id": "SEk5D7xwVy2D"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. `Implementation` - \"Standard Model\" 😉 Training and Evaluation"
      ],
      "metadata": {
        "id": "44TdMiajg-On"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 - Load the Models"
      ],
      "metadata": {
        "id": "WcPFxg3xgYBd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.1 - Loading the Transformer"
      ],
      "metadata": {
        "id": "zLGDRCxrV1VX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# - [X] TODO: Load the model.\n",
        "model = Transformer(config=config.model)\n",
        "\n",
        "# - [X] TODO: Understand HookedTransformer from TransformerLens: https://github.com/neelnanda-io/TransformerLens\n",
        "# model = HookedTransformer.from_pretrained(\"gelu-1l\").to(DTYPES[config[\"enc_dtype\"]])"
      ],
      "metadata": {
        "id": "15zw3V1ZgEUl"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.2 - Loading the Autoencoder"
      ],
      "metadata": {
        "id": "H54sR30UgFox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# - [ ] TODO: Reimplement autoencoder loading using custom model.\n",
        "# auto_encoder_run = \"run1\" # @param [\"run1\", \"run2\"]\n",
        "# encoder = AutoEncoder.load_from_hf(auto_encoder_run)"
      ],
      "metadata": {
        "id": "DEf0VTmgV_yk"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 - Train the model"
      ],
      "metadata": {
        "id": "WQ0ILsUtgi7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config.training.optimizer = torch.optim.AdamW(\n",
        "    params=model.parameters(), lr=config.training.learning_rate)\n",
        "test_data = train(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    data=data,\n",
        "    **config.training.to_dict()\n",
        ")"
      ],
      "metadata": {
        "id": "etrUAZYIgifj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0c54f40b367843b7b3909d6df28b33f1",
            "d85218137d254d49ad331e4be9af7dae",
            "3526fc44f5a9427bb14161b5c87b0c18",
            "be89efd8698a4560834211e728aaf759",
            "521bdaf10a39426e90dba01d9b70287c",
            "9bc5f4eafca84d9cadbdb439f60ff2a8",
            "f90cbcfbbee846d2948d7f1ab5bab1b7",
            "d44053627f0945d5957117fa6dfd18ca",
            "816c5324c9244d96a215635e0abe82b1",
            "4688f6948e1e485185f9d1c3569019b8",
            "e943203383134a209c38227748aff16a"
          ]
        },
        "outputId": "5417d8a7-1b73-4471-ffda-d87933d4cddf"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running training loop...:   0%|          | 0/8013769 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c54f40b367843b7b3909d6df28b33f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('i: 0, example:\\n'\n",
            " 'Port-au-Prince, Haiti (CNN) -- Earthquake victims, writhing in pain and '\n",
            " 'grasping at life, watched doctors and nurses walk away from a field hospital '\n",
            " 'Friday night after a Belgian medical team evacuated the area, saying it was '\n",
            " 'concerned about security.\\n'\n",
            " '\\n'\n",
            " 'The decision left CNN Chief Medical Correspondent Sanjay Gupta as the only '\n",
            " 'doctor at the hospital to get the patients through the night.\\n'\n",
            " '\\n'\n",
            " 'CNN initially reported, based on conversations with some of the doctors, '\n",
            " 'that the United Nations ordered the Belgian First Aid and Support Team to '\n",
            " 'evacuate. However, Belgian Chief Coordinator Geert Gijs, a doctor who was at '\n",
            " 'the hospital with 60 Belgian medical personnel, said it was his decision to '\n",
            " 'pull the team out for the night. Gijs said he requested U.N. security '\n",
            " 'personnel to staff the hospital overnight, but was told that peacekeepers '\n",
            " 'would only be able to evacuate the team.\\n'\n",
            " '\\n'\n",
            " 'He said it was a \"tough decision\" but that he accepted the U.N. offer to '\n",
            " 'evacuate after a Canadian medical team, also at the hospital with Canadian '\n",
            " 'security officers, left the site Friday afternoon. The Belgian team returned '\n",
            " 'Saturday morning.\\n'\n",
            " '\\n'\n",
            " 'Gijs said the United Nations has agreed to provide security for Saturday '\n",
            " 'night. The team has requested the Belgian government to send its own troops '\n",
            " 'for the field hospital, which Gijs expects to arrive late Sunday.\\n'\n",
            " '\\n'\n",
            " 'Responding to the CNN report that Gupta was the only doctor left at the '\n",
            " 'Port-au-Prince field hospital, U.N. spokesman Martin Nesirky said Saturday '\n",
            " \"that the world body's mission in Haiti did not order any medical team to \"\n",
            " 'leave. If the team left, it was at the request of their own organization, he '\n",
            " 'said.\\n'\n",
            " '\\n'\n",
            " 'Edmond Mulet, the U.N. assistant secretary general for peacekeeping '\n",
            " 'operations, told reporters later that local security officers deemed the '\n",
            " 'makeshift hospital unsafe.\\n'\n",
            " '\\n'\n",
            " '\"It seems that we\\'ve heard some reports in the international media that the '\n",
            " 'United Nations asked or forced some medical teams to not work any more in '\n",
            " 'some clinic -- that is not true, that is completely untrue,\" Mulet said '\n",
            " 'Saturday.\\n'\n",
            " '\\n'\n",
            " 'CNN video from the scene Friday night shows the Belgian team packing up its '\n",
            " 'supplies and leaving with an escort of blue-helmeted U.N. peacekeepers in '\n",
            " 'marked trucks.\\n'\n",
            " '\\n'\n",
            " \"View or add to CNN's database of missing persons in Haiti\\n\"\n",
            " '\\n'\n",
            " 'Gupta -- assisted by other CNN staffers, security personnel and at least one '\n",
            " 'Haitian nurse who refused to leave -- assessed the needs of the 25 patients, '\n",
            " 'but there was little they could do without supplies.\\n'\n",
            " '\\n'\n",
            " 'More people, some in critical condition, were trickling in late Friday.\\n'\n",
            " '\\n'\n",
            " '\"I\\'ve never been in a situation like this. This is quite ridiculous,\" Gupta '\n",
            " 'said.\\n'\n",
            " '\\n'\n",
            " \"With a dearth of medical facilities in Haiti's capital, ambulances had \"\n",
            " 'nowhere else to take patients, some of whom had suffered severe trauma -- '\n",
            " 'amputations and head injuries -- under the rubble. Others had suffered a '\n",
            " 'great deal of blood loss, but there were no blood supplies left at the '\n",
            " 'clinic.\\n'\n",
            " '\\n'\n",
            " 'Gupta feared that some would not survive the night.\\n'\n",
            " '\\n'\n",
            " 'He and the others stayed with the injured all night, after the medical team '\n",
            " 'had left and after the generators gave out and the tents turned pitch '\n",
            " 'black.\\n'\n",
            " '\\n'\n",
            " \"Gupta monitored patients' vital signs, administered painkillers and \"\n",
            " 'continued intravenous drips. He stabilized three new patients in critical '\n",
            " 'condition.\\n'\n",
            " '\\n'\n",
            " 'At 3:45 a.m., he posted a message on Twitter: \"pulling all nighter at haiti '\n",
            " 'field hosp. lots of work, but all patients stable. turned my crew into a '\n",
            " 'crack med team tonight.\"\\n'\n",
            " '\\n'\n",
            " 'Are you in Haiti and safe? Share your photos\\n'\n",
            " '\\n'\n",
            " 'He said the Belgian doctors did not want to leave their patients behind but '\n",
            " 'were ordered out by the United Nations, which sent buses to transport them.\\n'\n",
            " '\\n'\n",
            " '\"There is concern about riots not far from here -- and this is part of the '\n",
            " 'problem,\" Gupta said.\\n'\n",
            " '\\n'\n",
            " 'There have been scattered reports of violence throughout the capital.\\n'\n",
            " '\\n'\n",
            " '\"What is striking to me as a physician is that patients who just had '\n",
            " 'surgery, patients who are critically ill, are essentially being left here, '\n",
            " 'nobody to care for them,\" Gupta said.\\n'\n",
            " '\\n'\n",
            " 'Sandra Pierre, a Haitian who has been helping at the makeshift hospital, '\n",
            " 'said the medical staff took most of the supplies with them.\\n'\n",
            " '\\n'\n",
            " '\"All the doctors, all the nurses are gone,\" she said. \"They are expected to '\n",
            " 'be back tomorrow. They had no plan on leaving tonight. It was an order that '\n",
            " 'came suddenly.\"\\n'\n",
            " '\\n'\n",
            " 'She told Gupta, \"It\\'s just you.\"\\n'\n",
            " '\\n'\n",
            " \"A 7.0 magnitude earthquake flattened Haiti's capital city Tuesday afternoon, \"\n",
            " 'affecting as many as 3 million people as it fanned out across the island '\n",
            " 'nation. Tens of thousands of people are feared dead.\\n'\n",
            " '\\n'\n",
            " 'Haiti, the poorest nation in the Western hemisphere, lacked adequate medical '\n",
            " 'resources even before the disaster and has been struggling this week to tend '\n",
            " 'to huge numbers of injured. The clinic, set up under several tents, was a '\n",
            " 'godsend to the few who were lucky to have been brought there.\\n'\n",
            " '\\n'\n",
            " 'Retired Army Lt. Gen. Russel Honore, who led relief efforts for Hurricane '\n",
            " \"Katrina in 2005, said the evacuation of the clinic's medical staff was \"\n",
            " 'unforgivable.\\n'\n",
            " '\\n'\n",
            " '\"Search and rescue must trump security,\" Honoré said. \"I\\'ve never seen '\n",
            " 'anything like this before in my life. They need to man up and get back in '\n",
            " 'there.\"\\n'\n",
            " '\\n'\n",
            " 'Honoré drew parallels between the tragedy in New Orleans, Louisiana, and in '\n",
            " 'Port-au-Prince. But even in the chaos of Katrina, he said, he had never seen '\n",
            " 'medical staff walk away.\\n'\n",
            " '\\n'\n",
            " '\"I find this astonishing these doctors left,\" he said. \"People are scared of '\n",
            " 'the poor.\"\\n'\n",
            " '\\n'\n",
            " \"CNN's Justine Redman, Danielle Dellorto and John Bonifield contributed to \"\n",
            " 'this report.')\n",
            "('i: 100, example:\\n'\n",
            " 'Two of the three investigations into the actions of Salt Lake City Police '\n",
            " 'officers Detective Jeff Payne and Lt. James Tracy following Payne’s arrest '\n",
            " 'of University of Utah Health nurse Alex Wubbels have finished.\\n'\n",
            " '\\n'\n",
            " 'The first — the police department’s internal affairs investigation — '\n",
            " 'concluded that Tracy violated five departmental policies. It found that he '\n",
            " 'acted with conduct unbecoming of an officer. Other rules broken include '\n",
            " 'behaving with courtesy in public contacts, a policy favoring misdemeanor '\n",
            " 'citations over arrests ”whenever possible,” the code of ethics and a '\n",
            " 'standards of conduct policy.\\n'\n",
            " '\\n'\n",
            " 'It also found that Payne violated all five of those same policies, plus an '\n",
            " 'additional policy which required him to report his use of physical force '\n",
            " 'while arresting Wubbels — which he did not do.\\n'\n",
            " '\\n'\n",
            " 'Of Payne’s actions, the department wrote, “You demonstrated extremely poor '\n",
            " 'professional judgment (especially for an officer with 27 years of '\n",
            " 'experience), which calls into question your ability to effectively serve the '\n",
            " 'public and the Department in a manner that inspires the requisite trust, '\n",
            " 'respect, and confidence.”\\n'\n",
            " '\\n'\n",
            " 'To both employees, letters said, “disciplinary action, which may include '\n",
            " 'termination of your employment, is being considered in response to actions '\n",
            " 'on your part which appear to be a violation of policy and/or expectations '\n",
            " 'related to the performance of your job duties.”\\n'\n",
            " '\\n'\n",
            " 'Payne’s lawyer, Greg Skordas, responded to the internal investigation’s '\n",
            " 'results. He complimented their accounting of the facts but took issue with '\n",
            " 'some of the results. He said he feels the report wouldn’t have been so harsh '\n",
            " 'if the body camera footage hadn’t been publicly released and believes the '\n",
            " 'report will be used to “justify major discipline … when it’s not warranted '\n",
            " 'here.”\\n'\n",
            " '\\n'\n",
            " '“He made a terrible mistake … But let’s not overstate it because it’s become '\n",
            " 'a YouTube sensation,” Skordas said.\\n'\n",
            " '\\n'\n",
            " 'The second investigation — an independent review by the Civilian Review '\n",
            " 'Board — concluded with findings that Tracy did not meet the responsibilities '\n",
            " 'of his position as a watch commander, that both officers should have '\n",
            " 'contacted the department’s legal adviser and that both officers did not '\n",
            " 'understand the laws in question. It also found that Payne violated three '\n",
            " 'department policies — public courtesy, blood draw procedures and his '\n",
            " 'obligation to follow policy and orders.\\n'\n",
            " '\\n'\n",
            " 'The Civilian Review Board’s report also noted that no other police officer '\n",
            " 'or security personnel present at the time of the incident intervened. These '\n",
            " 'officers were from both SLCPD and the University of Utah’s campus police '\n",
            " 'department. The security there was employed by the hospital.\\n'\n",
            " '\\n'\n",
            " 'Wubbels and her lawyer have named the inaction of those individuals as one '\n",
            " 'of their primary concerns.\\n'\n",
            " '\\n'\n",
            " 'Their actions are also under ongoing criminal investigation by the Salt Lake '\n",
            " 'County District Attorney’s office, in coordination with the Unified Police '\n",
            " 'Department and the FBI.\\n'\n",
            " '\\n'\n",
            " 'Wubbels had called hospital security when Payne became agitated. They came, '\n",
            " 'but did not intervene in any way, telling her it was a “police matter” in '\n",
            " 'which they couldn’t “get involved.” When she asked a U police officer to '\n",
            " 'protect her from Payne, who was threatening her with arrest at the time, he '\n",
            " 'told her that he would not prevent Payne from arresting her if she '\n",
            " 'interfered with his work because her actions were obstruction of justice.\\n'\n",
            " '\\n'\n",
            " 'One U officer, Steven Worona, appears to assist in Payne’s arrest of Wubbels '\n",
            " 'by placing his hand on her shoulder to hold her still. After she was '\n",
            " 'arrested, he approached Payne and Tracy, offering to help them get the blood '\n",
            " 'they wanted.\\n'\n",
            " '\\n'\n",
            " 'In a video released online, U police Chief Dale Brophy said, “Having seen '\n",
            " 'the video and firsthand what she went through, and what she tried to do to '\n",
            " 'de-escalate and solve the problem, I think that somebody else — [university] '\n",
            " 'security and/or police — could have stepped up and taken that role from her '\n",
            " 'and been the advocate for her like they should’ve been.”\\n'\n",
            " '\\n'\n",
            " 'Brophy said he’s met with the department and instituted more de-escalation '\n",
            " 'training “to make sure it never happens again.”\\n'\n",
            " '\\n'\n",
            " 'On July 26, Payne went to the U’s hospital in search of a patient’s blood on '\n",
            " 'behalf of the Logan Police Department. When Wubbels refused to give him a '\n",
            " 'sample under policy agreed to by the hospital and SLCPD, Payne arrested her '\n",
            " 'and pulled her out of the hospital while she screamed for help. Tracy, '\n",
            " 'Payne’s supervisor that day, arrived shortly after the arrest. He had '\n",
            " 'ordered her arrest.\\n'\n",
            " '\\n'\n",
            " 'Payne and Tracy have both worked as police officers for decades. Payne has '\n",
            " 'won multiple awards for his work, including a Purple Heart award from the '\n",
            " 'Utah Peace Officer’s Association after being shot during a traffic stop. '\n",
            " 'Tracy has held several leadership positions in the force.\\n'\n",
            " '\\n'\n",
            " 'Both have been reprimanded in the past. In 2013, then-Chief Chris Burbank '\n",
            " 'gave a written reprimand to Payne over allegations that he had sexually '\n",
            " 'harassed a female coworker over a long period of time, including unwanted '\n",
            " 'physical contact. He had also been suspended in 1995 after a police chase in '\n",
            " 'which he violated several department policies. Tracy’s only formal reprimand '\n",
            " 'was in 1997 after he arrested two people, then released them on the other '\n",
            " 'side of the city, never documenting what happened.\\n'\n",
            " '\\n'\n",
            " 'Payne and Tracy now have until Oct. 3 to respond to the results of the '\n",
            " 'internal affairs investigation. After that time period, SLCPD Chief Mike '\n",
            " 'Brown will make a decision about the consequences the two officers will '\n",
            " 'face.\\n'\n",
            " '\\n'\n",
            " 'e.vandersteen@dailyutahchronicle.com\\n'\n",
            " '\\n'\n",
            " '@EliseAbril')\n",
            "('i: 200, example:\\n'\n",
            " 'The GDP-growth figure released today, at 3.5%, was slightly higher than '\n",
            " 'expected, but camouflages the mounting economic cost of the 2014 coup. '\n",
            " 'Thailand’s output gap is now among the biggest in Asia; the economy is being '\n",
            " 'kept afloat by government spending and foreign tourists’ cash. But last '\n",
            " 'week’s bombings may deter visitors, and autocratic rule is stifling economic '\n",
            " 'progress. Household debt is at a historic high; low agricultural prices have '\n",
            " 'depressed farm incomes. The country’s old-style route to prosperity is '\n",
            " 'blocked: exports will fall for the fourth consecutive year in 2016. '\n",
            " 'Thailand’s economy is bigger than those of fast-growing Vietnam, Myanmar, '\n",
            " 'Laos and Cambodia combined. But its population is ageing and economic policy '\n",
            " 'is deeply conservative. Future growth will have to come from capital '\n",
            " 'accumulation or increases in productivity. Yet the new constitution puts the '\n",
            " 'army in charge, making it responsible for the economy, education and '\n",
            " 'innovation. What could possibly go wrong?')\n",
            "('i: 300, example:\\n'\n",
            " 'Mars Observer was one of three NASA Mars missions lost in the 1990s because '\n",
            " 'of technical errors, and not as part of a broader conspiracy. The dark side '\n",
            " 'of space disaster theories Space disasters attract so much public attention '\n",
            " 'and often involve such complex and subtle sequences of events that there’s '\n",
            " 'an entire Internet literature of “crackpot causes” on par with JFK '\n",
            " 'assassination myths. To the degree that innovative analysis is often '\n",
            " 'critical to reconstructing—from partial and often garbled evidence—a '\n",
            " 'shocking causal sequence leading from goodness to disaster, the initial '\n",
            " 'investigation period demands that critical judgment be held somewhat in '\n",
            " 'check so as not to discourage imagination. However, once a logical '\n",
            " 'reconstruction gels, is tested, and then is ultimately verified by being '\n",
            " 'implemented and hence reducing future flight hazards, that official '\n",
            " 'explanation achieves a substantial level of authenticity. But not to '\n",
            " 'everyone’s satisfaction, apparently, as a search of still-thriving '\n",
            " 'non-traditional explanations of the Apollo 1 fire, the Apollo 13 breakdown, '\n",
            " 'the Challenger disintegration, and the Columbia catastrophe, whose fifth '\n",
            " 'anniversary now approaches. For example, in the case of Columbia, YouTube is '\n",
            " 'full of videos from self-styled experts still convinced a freak bolt of '\n",
            " 'ionospheric lightning crippled the spaceship. A famous photograph supposedly '\n",
            " 'shows that bolt, even though space experts have long been satisfied that the '\n",
            " 'bizarre image was merely the result of camera jiggle during a time-lapse '\n",
            " 'exposure. Apart from the comic relief value of such crackpot ideas, there’s '\n",
            " 'a darker aspect of this kind of cultural pathology, just as there are '\n",
            " 'serious analyses pointing to the socially toxic effects of the JFK '\n",
            " 'assassination “alternate theories”. For spaceflight, being distracted by the '\n",
            " 'wrong cause means being tempted by the wrong fix. That’s never amusing, and '\n",
            " 'often can be expensive. For spaceflight, being distracted by the wrong cause '\n",
            " 'means being tempted by the wrong fix. That’s never amusing, and often can be '\n",
            " 'expensive. As an egregious “bad example” of wrong causes, a recent book '\n",
            " '(Dark Mission, by Richard Hoagland and Michael Bara) spent a lot of time '\n",
            " 'muddying the waters over a series of NASA Mars mission failures in the '\n",
            " '1990s. This isn’t just some remote corner of an intellectual ghetto on the '\n",
            " 'Internet—the book came within one tick mark of making it onto the New York '\n",
            " 'Times bestsellers list for paperback non-fiction (it reached #21 '\n",
            " 'nationwide). So as an exercise in cultural self-defense and in proselytizing '\n",
            " 'sound “space safety” history, here is a detailed look at the claims, the '\n",
            " 'delusions, and the errors in that book’s treatment of these space accidents. '\n",
            " 'Mars Observer (1993) Dark Mission portrays the failure of the Mars Observer '\n",
            " 'probe in 1993 as a deliberate act by NASA to prevent the publication of its '\n",
            " 'expected photographs of artificial Martian ruins. But the description of the '\n",
            " 'events is inconsistent with well-documented accounts, reports non-existent '\n",
            " 'events, and omits well-known explanations for important features of the '\n",
            " 'probe’s flight plan. All of this can be easily confirmed through Internet '\n",
            " 'searches. Dark Mission, pp. 87–88: “NASA, in another unprecedented move, had '\n",
            " 'inexplicably ordered Mars Observer to shut off its primary data stream prior '\n",
            " 'to executing a key pre-orbital burn… Because NASA had violated the first '\n",
            " 'rule of space travel—you never turn off the radio—no cause for the probe’s '\n",
            " 'loss was ever satisfactorily determined.” Actually, whether a radio is '\n",
            " 'turned on or off, practically all orbital insertion burns on lunar and '\n",
            " 'planetary missions occur out of radio contact. This is a result of the '\n",
            " 'geometric alignment of the probe passing behind the planet (or moon) and '\n",
            " 'hence having its radio signals blocked. So keeping a probe’s radio turned on '\n",
            " 'during these periods is about as useless as installing windshield wipers. To '\n",
            " 'my knowledge, there is no “first rule of spaceflight” about never turning '\n",
            " 'radios off. Interplanetary probes do this all the time. The “rule” is '\n",
            " 'imaginary. I can’t find any documentation anywhere that provides this '\n",
            " '“rule”. I suspect that the Dark Mission authors just imagined it. The '\n",
            " 'maneuver that Mars Observer was to perform was not even, as Dark Mission '\n",
            " 'claims, a “key pre-orbital burn”. It was not a burn of any kind. Instead, it '\n",
            " 'was the firing of explosive bolts to open two pressurant tanks that would '\n",
            " 'allow the fuel to be pushed into the probe’s engines several days later. '\n",
            " 'There is nothing “inexplicable” about turning off the radio for the firing '\n",
            " 'of the pyrotechnic bolts. The sharp shock of the detonations was thought to '\n",
            " 'be a hazard to the hot filament in a key radio component, which is much less '\n",
            " 'brittle when cold. Hot filaments can shatter under shocks that cold ones '\n",
            " 'wouldn’t even notice. This is clearly explained in on-ine documents, '\n",
            " 'including the accident report. You only have to search “Mars Observer '\n",
            " 'accident report” to be led right to the 313-page “Failure Investigation '\n",
            " 'Board Report”. Keeping a probe’s radio turned on during orbit insertion '\n",
            " 'burns is about as useless as installing windshield wipers. Why was the radio '\n",
            " 'turned off? “In accordance with the mission’s published flight rules, the '\n",
            " 'transmitter on the spacecraft had been turned off during the propellant-tank '\n",
            " 'Pressurization Sequence on 21 August… To protect the spacecraft radio '\n",
            " 'frequency transmitter from damage during the Pressurization Sequence (albeit '\n",
            " 'a very low probability), the software included a command to turn off the '\n",
            " 'Mars Observer transponder and radio frequency (RF) telemetry power amplifier '\n",
            " 'for a period of ten minutes. This was a standard procedure that had been '\n",
            " 'implemented several times earlier during the mission.” The report gave '\n",
            " 'further details: “This sequence included the firing of two normally-closed '\n",
            " 'pyrotechnic valves, that would allow high-pressure gaseous helium to '\n",
            " 'pressurize the nitrogen tetroxide oxidizer tank and the monomethyl hydrazine '\n",
            " 'fuel tank.” More on p. 25 of the report: “Concern existed in the Mars '\n",
            " 'Observer project team that the pyro-firing event might damage the traveling '\n",
            " 'wave tube amplifiers in the spacecraft telecommunications system if the '\n",
            " 'amplifiers were left on.” Nor is it true that “no cause for the probe’s loss '\n",
            " 'was ever satisfactorily determined”, as Dark Mission claims. To the '\n",
            " 'contrary, in hindsight it was excruciatingly clear what almost certainly '\n",
            " 'happened. “The Board was unable to find clear and conclusive evidence '\n",
            " 'pointing to a particular scenario as the ‘smoking gun’,” the report '\n",
            " 'explained, but “the Board concluded through a process of elimination that '\n",
            " 'the most probable cause of the loss of downlink from the Mars Observer was a '\n",
            " 'massive failure of the pressurization side of the propulsion system. The '\n",
            " 'Board also concluded that the most probable cause of that failure was the '\n",
            " 'unintended mixing of nitrogen tetroxide (NTO) and monomethyl hydrazine (MMH) '\n",
            " 'in the titanium tubing on the pressurization side of the propulsion system. '\n",
            " 'This mixing was believed by the Board to have been enabled by significant '\n",
            " 'NTO migration through check valves during the eleven-month cruise phase from '\n",
            " 'Earth to Mars. This conclusion is supported (but not proven) by NTO '\n",
            " 'transport-rate data acquired by JPL, by NTO/MMH reaction simulations '\n",
            " 'performed by [the Naval Research Laboratory], and by NTO/MMH mixing tests '\n",
            " 'performed by AFPL [Air Force Propulsion Labs].” As to why the propulsions '\n",
            " 'system hardware, adapted from a military prop module that normally needed a '\n",
            " 'lifetime of only 12 hours, was used for a year-long mission, the report '\n",
            " 'added that “Too much reliance was placed on the heritage of spacecraft '\n",
            " 'hardware, software, and procedures, especially since the Mars Observer '\n",
            " 'mission was fundamentally different from the missions of the satellites from '\n",
            " 'which the heritage was derived.” It specifically criticized the propulsion '\n",
            " 'system for “Inappropriate isolation mechanisms between fuel and oxidizer for '\n",
            " 'an interplanetary mission.” “The original [money-saving] philosophy of minor '\n",
            " 'modifications to a commercial production-line spacecraft was retained '\n",
            " 'throughout the program,” the report continued. “The result was reliance on '\n",
            " 'design and component heritage qualification that was inappropriate for the '\n",
            " 'mission. Examples of this reliance were the failure to qualify the traveling '\n",
            " 'wave tube amplifiers for pyro firing shock [and] the design of the '\n",
            " 'propulsion system.” Whether or not this particular proposed failure mode is '\n",
            " 'plausible (and from my own research I’ve concluded it was very plausible), '\n",
            " 'it remains untrue to state (as Dark Mission does) that turning off the radio '\n",
            " 'was “inexplicable” (and a violation of a “rule number one”) and that no '\n",
            " 'satisfactory explanation for the failure was ever determined. Leaving out '\n",
            " 'these easily-available views resulted in a passage that I think was '\n",
            " 'incomplete and misleading. Mars Polar Lander (1999) I noted several Dark '\n",
            " 'Mission references to me personally that deal with the 1999 failure of the '\n",
            " 'Mars Polar Lander (MPL) probe. On page 316: “James Oberg published a story '\n",
            " 'on UPI that accused JPL employees of knowing full well that the MPL was '\n",
            " 'doomed (due to software problems related to the spacecraft’s landing legs) '\n",
            " 'from very early on in the mission.” On page 317 this is called a “bizarre '\n",
            " 'UPI accusation”. The brief account of the UPI article is garbled almost '\n",
            " 'beyond recognition, casting serious doubts on the reading comprehension '\n",
            " 'level of the author who did this section. In the one-sentence summary '\n",
            " '(“James Oberg published a story on UPI that accused JPL employees of knowing '\n",
            " 'full well that the MPL was doomed due to software problems related to the '\n",
            " 'spacecraft’s landing legs from very early on in the mission”), practically '\n",
            " 'every word is wrong. Alleged foreknowledge of the impending failure had '\n",
            " 'nothing to do with software. The article stated: As explained privately to '\n",
            " 'UPI, the Mars Polar Lander vehicle’s braking thrusters had failed acceptance '\n",
            " 'testing during its construction. But rather than begin an expensive and '\n",
            " 'time-consuming redesign, an unnamed space official simply altered the '\n",
            " 'conditions of the testing until the engine passed. “They tested the [engine] '\n",
            " 'ignition process at a temperature much higher than it would be in flight,” '\n",
            " 'UPI’s source said. This was done because when the [engines] were first '\n",
            " 'tested at the low temperatures predicted after the long cruise from Earth to '\n",
            " 'Mars, the ignition failed or was too unstable to be controlled. So the test '\n",
            " 'conditions were changed in order to certify the engine performance. But the '\n",
            " 'conditions then no longer represented those most likely to occur on the real '\n",
            " 'space flight. “I’m as certain as I can be that the thing blew up,” the '\n",
            " 'source concluded. That potential failure mode was not known “from very early '\n",
            " 'on in the mission”, but only at the very end: “Following the September loss '\n",
            " 'of the first spacecraft due to management errors, NASA had initiated a crash '\n",
            " 'review of the Mars Polar Lander to identify any similar oversights. '\n",
            " 'According to UPI’s source, the flaws in the [engine] testing were uncovered '\n",
            " 'only a few days before the landing was to occur on December 3. By then it '\n",
            " 'was too late to do anything about it.” The brief account of the UPI article '\n",
            " 'is garbled almost beyond recognition, casting serious doubts on the reading '\n",
            " 'comprehension level of the author who did this section. The specific '\n",
            " 'software problem with the landing leg sensor scenario was not known before '\n",
            " 'the landing at all, and the UPI article clearly states that it was '\n",
            " 'discovered after the crash: “The Mars Polar Lander investigation team has '\n",
            " 'also reportedly identified a second fatal design flaw that would have doomed '\n",
            " 'the probe even if the engines had functioned properly. Post-accident tests '\n",
            " 'have shown that when the legs are initially unfolded during the final '\n",
            " 'descent, springs push them so hard that they ‘bounce’ and trigger the '\n",
            " 'microswitches by accident. As a result, the computer receives what it '\n",
            " 'believes are indications of a successful touchdown, and it shuts off the '\n",
            " 'engines. Ground testing prior to launch apparently never detected this '\n",
            " 'because each of the tests was performed in isolation from other tests. One '\n",
            " 'team verified that the legs unfolded properly. Another team verified that '\n",
            " 'the microswitches functioned on landing.” In a simple reading comprehension '\n",
            " 'verification test, this one incident indicates a severe problem with the '\n",
            " 'book’s authors’ ability to understand, and restate, simple English about '\n",
            " 'space technology. In one sentence, there were three swings, and three '\n",
            " 'misses—three strikes. By the way, after NASA’s official denunciations of the '\n",
            " 'UPI story I had written (I have the honor of being the only journalist ever '\n",
            " 'denounced by name in an official NASA press release), the story turned out '\n",
            " 'even worse than I had written. Space engineers hadn’t fudged the test '\n",
            " 'results, after all. My source was wrong about this, this time, the first '\n",
            " 'occasion in a long sequence of accurate leaks. What was far worse was that '\n",
            " 'NASA had decided that any such tests weren’t even necessary. The engine '\n",
            " 'ignition system was never tested at temperatures expected out at Mars, '\n",
            " 'because (JPL said) the engine had already flown in space on some other '\n",
            " 'mission and so didn’t need to be requalified. But NASA press officials, '\n",
            " 'despite repeated inquiries from me and promises of cooperation from them, '\n",
            " 'never disclosed the space mission(s) that these special engines had been '\n",
            " 'originally flown on. The same design engines are installed aboard the Mars '\n",
            " 'Phoenix lander now on route. Hopefully, improvements have been made. page 2: '\n",
            " 'Mars Climate Orbiter >>')\n",
            "('i: 400, example:\\n'\n",
            " 'Sometimes, a bra can look too small when it fits well, because the strip of '\n",
            " 'fabric/elastic under the top of the lace is too tight across the top of the '\n",
            " 'breast. European bras, in particular are nearly infamous for this. If you '\n",
            " 'have firm breast tissue, your breasts will fight against the elastic and '\n",
            " 'shape the bra. Not all of us are that lucky. Soft tissue molds to the shape '\n",
            " 'of the bra, so the elastic pulls down over the top of the breast. If the bra '\n",
            " 'is not a full coverage style, it will not sit against the breastbone, but '\n",
            " 'actually against the breast tissue, causing the breasts to bulge out of the '\n",
            " 'top of the bra and give the appearance of a bra that is too small.\\n'\n",
            " '\\n'\n",
            " 'This seam is put in place to pull the top of the cup closer to the chest and '\n",
            " 'prevent the bust from spilling out. That’s probably just fine for someone '\n",
            " 'who is predominantly full on bottom, but someone with a more even or full on '\n",
            " 'top shape will run into this problem pretty consistently in European bras, '\n",
            " 'so I’m going to talk about how to fix that.\\n'\n",
            " '\\n'\n",
            " 'Tools You’ll Need:\\n'\n",
            " '\\n'\n",
            " '1 seam ripper & 1 pair of scissors.\\n'\n",
            " '\\n'\n",
            " 'Seriously, that’s it.\\n'\n",
            " '\\n'\n",
            " 'Difficulty Level: Easy. Seriously, a well behaved toddler could do it.\\n'\n",
            " '\\n'\n",
            " 'The bra I will be performing this alteration on is the Samanta Hana (A122 '\n",
            " 'cut) in 70I. Samanta is a Polish brand, and I will refrain from discussing '\n",
            " 'the finer points of the style in detail, as the brand has already been '\n",
            " 'broken down quite well by Miss Underpinnings, but I will say for the purpose '\n",
            " 'of this post that I would refer to this as a mesh balconette.\\n'\n",
            " '\\n'\n",
            " 'As you can see above, the bra looks too small on close up. I’m clearly '\n",
            " 'bulging out the top of the cup. If you look closely at the top center, you '\n",
            " 'can even see my bust trying to escape through the gaps in the lace. What may '\n",
            " 'not be obvious in photographs is that there is actually plenty of room in '\n",
            " 'this cup for me, but the top of the cup is being pulled down very tightly '\n",
            " 'across the top of my breast, causing me to quadboob even though the bra '\n",
            " 'actually fits.\\n'\n",
            " '\\n'\n",
            " 'This is the problem:\\n'\n",
            " '\\n'\n",
            " 'This seam is slightly elastic, and so makes the top of the cup too closed '\n",
            " 'off for me. It fits beautifully everywhere else.\\n'\n",
            " '\\n'\n",
            " 'Now, you’re going to work from the inside of the bra. Grab your seam ripper. '\n",
            " 'We need to remove the stitches from inside of the elastic.\\n'\n",
            " '\\n'\n",
            " 'You want to work from the elastic side to avoid potentially tearing any mesh '\n",
            " 'or lace with your seam ripper. You can stab a piece of elastic to your '\n",
            " 'hearts content and it doesn’t really matter, but stab a bit of lace and you '\n",
            " 'might poke a hole in your bra.\\n'\n",
            " '\\n'\n",
            " 'As you start to remove these stitches, you’ll see the elastic start to come '\n",
            " 'away from the bra, like so:\\n'\n",
            " '\\n'\n",
            " 'Keep going. You have to remove all of them. At which point, you’ll have '\n",
            " 'something that looks like this:\\n'\n",
            " '\\n'\n",
            " 'Now, up to this point, we’re doing fine. We haven’t cut anything. We are '\n",
            " 'still at a place where this alteration can be reversed by sewing the elastic '\n",
            " 'back down, but we won’t be for long.\\n'\n",
            " '\\n'\n",
            " 'This alteration always has the potential to open the cup too much for you '\n",
            " '(You can correct this by sewing a dart near the wire, but that’s another '\n",
            " 'alteration.), so you definitely want to try the bra on again at this point '\n",
            " 'to make sure the alteration is going to work for you before you move onto '\n",
            " 'the next step, at which point the alteration can not be reversed.\\n'\n",
            " '\\n'\n",
            " 'As you can see, this is probably going to work out well for me. There’s a '\n",
            " 'tiny bit of gaping, but that’s mostly due to the position I have to put my '\n",
            " 'arm in to take the photo and the elastic still being connected on both '\n",
            " 'ends.\\n'\n",
            " '\\n'\n",
            " 'You’re done with the seam ripper now. Grab the scissors. We need to cut the '\n",
            " 'elastic out on both sides beside the wire.\\n'\n",
            " '\\n'\n",
            " 'Cut as close to the wire as possible.\\n'\n",
            " '\\n'\n",
            " 'That’s it. The alteration is complete. There is no need to finish the '\n",
            " 'elastic or add no fray. You’re welcome to if you’d like, but if you cut it '\n",
            " 'as close to the wire as you can, the bra won’t give you any issues with '\n",
            " 'fraying or loose threads, and you won’t really even notice that there was '\n",
            " 'ever a seam there in the first place.\\n'\n",
            " '\\n'\n",
            " 'This is what you’ve removed – you don’t need them, so unless you have some '\n",
            " 'other use planned for them, just throw them out.\\n'\n",
            " '\\n'\n",
            " 'And this is what your bra will look like when it’s done:\\n'\n",
            " '\\n'\n",
            " 'The Final Fit Test:\\n'\n",
            " '\\n'\n",
            " 'This bra now fits me pretty darn well. It will gape slightly when I move my '\n",
            " 'arms certain ways, but not enough to make me fall out, not enough to cause '\n",
            " 'fit issues, and not enough to show under clothing. This alteration has made '\n",
            " 'this bra the best fit of my current rotation.\\n'\n",
            " '\\n'\n",
            " 'If I hadn’t altered it, I would only be able to wear it under loose t-shirts '\n",
            " 'and tunics, and so it would probably spend most of its time in the back of '\n",
            " 'the lingerie drawer.\\n'\n",
            " '\\n'\n",
            " 'If this is a problem you find you run into consistently, this is an '\n",
            " 'alteration you definitely want to consider. The entire alteration can be '\n",
            " 'completed in less than 30 minutes, and there is absolutely no sewing '\n",
            " 'required.\\n'\n",
            " '\\n'\n",
            " 'Advertisements')\n",
            "('i: 500, example:\\n'\n",
            " 'Looks like the TARDIS fell out of the Time Vortex and landed in an strange '\n",
            " \"new dimension.Honestly, I can't believe I haven't seen something like this \"\n",
            " \"before. Now I'm not saying one doesn't exist, just that I haven't seen \"\n",
            " 'it.Anyway, I think it turned out well. Took me forever to find a TARDIS '\n",
            " 'picture from a good angle to get the desired result.I especially like Ditzy '\n",
            " \"Doo's expression here.---FIRST EDIT, Nov. 27, 2011:Changed the color of the \"\n",
            " 'TARDIS light to better match the show. For some reason, I thought it blue. I '\n",
            " 'also added a faint green glow to the Doctor and Ditzy, emanating from the '\n",
            " 'TARDIS interior.--Doctor Whooves vector made by * Zork-787 Ditzy Doo/Derpy '\n",
            " 'Hooves vector made by ~ solusjbj TARDIS photo belongs to the BBC [link]')\n",
            "('i: 600, example:\\n'\n",
            " 'USA Buys Enough Guns in 3 Months to Outfit the Entire Chinese and Indian '\n",
            " 'Army\\n'\n",
            " '\\n'\n",
            " 'Law abiding US citizens bought on average 3,177,256 guns every 3 months in '\n",
            " '2008.\\n'\n",
            " '\\n'\n",
            " 'EveryTown, USA – -(AmmoLand.com)- In just 3 months Americans bought enough '\n",
            " \"guns to outfit the entire Chinese and Indian army's combined.\\n\"\n",
            " '\\n'\n",
            " '“You cannot invade the mainland United States. There would be a rifle behind '\n",
            " 'every blade of grass.” – Admiral Isoroku Yamamoto WWII\\n'\n",
            " '\\n'\n",
            " 'You also bought 1,529,635,000 rounds of ammunition in just the month of '\n",
            " 'December 2008. Yeah that is right, that is Billion with a “B”. This number '\n",
            " 'takes no accounting of reloading or reloaded ammunition.\\n'\n",
            " '\\n'\n",
            " 'This is an evaluation of overall firearms and ammunition purchases based on '\n",
            " 'low end numbers per Federal NIC instacheck data base Statistics. The numbers '\n",
            " 'presented are only PART of the overall numbers of arms and ammunition that '\n",
            " 'have been sold. The actual numbers are much higher.\\n'\n",
            " '\\n'\n",
            " 'Follow Up:')\n",
            "('i: 700, example:\\n'\n",
            " 'Apple will add all iPhone 4 models, the late 2010 13-inch MacBook Air, '\n",
            " 'third-generation AirPort Extreme, and mid 2009 AirPort Time Capsule to its '\n",
            " 'vintage and obsolete products list starting October 31, according to '\n",
            " 'Japanese website Mac Otakara Apple products on the vintage and obsolete list '\n",
            " 'are no longer eligible for hardware service, beyond a few exceptions. Apple '\n",
            " 'defines vintage products as those that have not been manufactured for more '\n",
            " 'than five years but less than seven years ago, while obsolete products are '\n",
            " 'those that were discontinued more than seven years ago. Each of the products '\n",
            " 'added were released between 2009 and 2010.The report specifically pertains '\n",
            " \"to Apple's vintage and obsolete products list in Japan, but the new \"\n",
            " 'additions will more than likely extend to the United States, Australia, '\n",
            " 'Canada, and the rest of the Asia-Pacific and Europe regions.Apple already '\n",
            " 'obsoleted CDMA models of the iPhone 4 around the world last month, while the '\n",
            " 'late 2010 MacBook Air joins the mid 2009 iMac, 2010 Mac mini, and mid 2010 '\n",
            " \"15-inch and 17-inch MacBook Pro among Apple's recently obsoleted \"\n",
            " 'notebooks.macOS Sierra remains compatible with the late 2010 MacBook Air, '\n",
            " 'while the iPhone 4 cannot be updated beyond iOS 7.1.2. Read how to identify '\n",
            " 'your MacBook Air model or how to identify your iPhone model The current '\n",
            " 'MacBook Air has not been updated in 584 days. Refreshed models with USB-C '\n",
            " 'ports are expected later this month at the earliest.')\n",
            "('i: 800, example:\\n'\n",
            " 'Saying that the Pledge of Allegiance has no educational value, an activist '\n",
            " 'group is pushing for Brookline to stop recitations of the pledge in public '\n",
            " 'schools.\\n'\n",
            " '\\n'\n",
            " 'Members of Brookline PAX are asking the Town Meeting this fall to vote in '\n",
            " 'favor of a resolution calling for the town’s School Committee to rescind its '\n",
            " 'pledge policy and stop it from being recited in the schools.\\n'\n",
            " '\\n'\n",
            " 'Martin Rosenthal, the cochairman of Brookline PAX, said that although the '\n",
            " 'recitation of the pledge is voluntary, there is subtle and sometimes overt '\n",
            " 'pressure on students, especially younger children, to participate.\\n'\n",
            " '\\n'\n",
            " '“It just puts kids in an uncomfortable situation,’’ Rosenthal said. “How do '\n",
            " 'you say that to a 6-year-old? . . . We just don’t think it belongs in the '\n",
            " 'schools.’’\\n'\n",
            " '\\n'\n",
            " 'The article Brookline PAX submitted for Town Meeting comes just months after '\n",
            " 'the town’s School Committee approved a revised policy requiring principals '\n",
            " 'to allow a weekly recitation of the pledge during morning announcements. '\n",
            " 'Participation in the recitations is left up to the individuals at the '\n",
            " 'schools.\\n'\n",
            " '\\n'\n",
            " 'The School Committee chairwoman, Rebecca Stone, said the new policy was '\n",
            " 'approved in the spring after discussion began over saying the pledge at the '\n",
            " 'Devotion School, where recitations were not a regular occurrence. While '\n",
            " 'weekly recitations of the pledge had been held at most Brookline K-through-8 '\n",
            " 'schools, the pledge also was not said regularly at the Lincoln School.\\n'\n",
            " '\\n'\n",
            " 'Stone said it has been a historical practice to say the pledge.\\n'\n",
            " '\\n'\n",
            " '“I agree with [Rosenthal] that it’s not of great educational value,’’ she '\n",
            " 'said. “We’re recognizing established and in some cases revered practices of '\n",
            " 'the citizenry.’’\\n'\n",
            " '\\n'\n",
            " 'Misti Jaynes, who has two children in Brookline’s Devotion School, said she '\n",
            " 'is glad that her children began having the opportunity to say the pledge at '\n",
            " 'school in April. Jaynes and several other parents lobbied the School '\n",
            " 'Committee in April for recitations, and she supports saying the pledge to '\n",
            " 'show patriotism and to bring Americans together.\\n'\n",
            " '\\n'\n",
            " '“If someone else doesn’t want to say it that is fine, but don’t take it away '\n",
            " 'from my children,’’ Jaynes said. “Don’t take away my rights.’’\\n'\n",
            " '\\n'\n",
            " 'Rosenthal, who has a daughter at Brookline High School, called the pledge a '\n",
            " 'loyalty oath loaded with complex issues.\\n'\n",
            " '\\n'\n",
            " '“Are you supposed to just say something like this,’’ he asked, “or are you '\n",
            " 'supposed to think about it?’’\\n'\n",
            " '\\n'\n",
            " 'Brock Parker can be reached at Brock.globe@gmail.com.\\n'\n",
            " '\\n'\n",
            " '© Copyright 2011 Globe Newspaper Company.')\n",
            "('i: 900, example:\\n'\n",
            " 'Mayor Rob Ford and Councillor Doug Ford are being taken to court by Toronto '\n",
            " 'resident and activist Jude MacDonald for allegedly violating the Municipal '\n",
            " 'Conflict Of Interest Act. This is the second time the mayor has faced such '\n",
            " 'charges but the first go-round for his brother.\\n'\n",
            " '\\n'\n",
            " 'In the application, filed in Superior Court by lawyer Tim Gleason, MacDonald '\n",
            " 'alleges that the Fords improperly mixed their personal and public interests '\n",
            " 'by speaking and/or voting on a slew of council items that directly or '\n",
            " 'indirectly affected clients of their family business, Deco Labels and Tags.\\n'\n",
            " '\\n'\n",
            " \"The identities of nearly all of Deco's clients remained a well-kept secret \"\n",
            " 'until this past summer, when Globe reporters viewed an internal list. The '\n",
            " \"majority of allegations in MacDonald's application stem from the paper's \"\n",
            " 'resulting story that highlighted several instances in which the Fords '\n",
            " \"advanced policies that aligned with their clients' interests.\\n\"\n",
            " '\\n'\n",
            " 'Porter Airlines, for example, was among the firms that have reportedly '\n",
            " 'contracted printing from Deco. And not only was Mayor Ford the salesperson '\n",
            " 'listed on the account, according to the Globe, but Deco \"salespeople - '\n",
            " 'including the Fords - receive commissions whenever one of their accounts '\n",
            " 'places an order.\"\\n'\n",
            " '\\n'\n",
            " 'As chief magistrate, Ford has taken a very active interest in facilitating '\n",
            " \"Porter's request for jets at the Island airport and has never once declared \"\n",
            " \"a conflict on the matter. (It's worth noting that if John Tory were to \"\n",
            " 'become mayor, he would very likely have a conflict on the same issue.)\\n'\n",
            " '\\n'\n",
            " 'Other alleged conflicts include:\\n'\n",
            " '\\n'\n",
            " '• voting on a motion pertaining to an industrial wastewater treatment '\n",
            " 'program in which both Deco itself and one of its clients were enrolled;\\n'\n",
            " '\\n'\n",
            " '• voting on and advocating against a new set of \"healthy vending criteria\" '\n",
            " 'for vending machines in rec centres that would have adversely affected Deco '\n",
            " 'client Coca-Cola;\\n'\n",
            " '\\n'\n",
            " '• voting on and advocating against a ban on the sale of bottled water at '\n",
            " 'City facilities that adversely affected Deco clients Nestlé Canada and '\n",
            " 'Coca-Cola (which produces Dasani);\\n'\n",
            " '\\n'\n",
            " '• and voting on and advocating for the appointment of Darius Mosun - chair '\n",
            " 'and CEO of Deco client Soheil Mosun - to the board of the Toronto Parking '\n",
            " 'Authority.\\n'\n",
            " '\\n'\n",
            " 'If either or both Fords are found to have violated the Act, the judge must '\n",
            " 'declare their seat(s) vacant and may disqualify them from holding office for '\n",
            " \"up to seven years. (It's not immediately clear how the first, mandatory \"\n",
            " \"penalty might apply to a Council member who's switched offices since a \"\n",
            " \"breach occurred, but it's likely that the second, discretionary penalty \"\n",
            " 'could be used to the same effect.) If, however, the Fords successfully argue '\n",
            " 'that a conflict came about through inadvertence or an error in judgment, or '\n",
            " 'that their interest was so remote as to be unlikely to have influenced them, '\n",
            " \"they're off the hook.\\n\"\n",
            " '\\n'\n",
            " 'In November 2012, a Superior Court judge ruled that Ford broke the Act when '\n",
            " 'he voted to overturn an earlier Council decision ordering him to repay money '\n",
            " \"he'd solicited from lobbyists for his football foundation. The judge ordered \"\n",
            " 'the mayor out of office, but the Divisional Court overturned the ruling on a '\n",
            " 'technicality.\\n'\n",
            " '\\n'\n",
            " 'This is at least the fourth notice of civil action served on Rob Ford since '\n",
            " 'becoming mayor, and at least the second for Doug since becoming councillor. '\n",
            " '(An additional defamation suit, brought by Boardwalk Pub owner George '\n",
            " 'Foulidis, was commenced just prior to the last election.)\\n'\n",
            " '\\n'\n",
            " \"The court application and MacDonald's accompanying affidavit are below.\")\n",
            "('i: 1000, example:\\n'\n",
            " 'And pretty much every spread shows underlying techniques and tricks you '\n",
            " 'likely never thought of. For instance, a simple quinoa salad with '\n",
            " \"cauliflower--it just requires a pressure cooker, and it's really fast--it \"\n",
            " 'takes just four minutes of cooking for the quinoa, something that never '\n",
            " 'occurred to me to try, and includes the tip of freezing a baking sheet to '\n",
            " 'cool the cooked grain for the salad. And cauliflower is rendered palatable '\n",
            " '(i.e., invisible) to doubters by being shaved over a mandoline or grated on '\n",
            " 'a Microplane grater, mixed with green apple, celery, pine nuts, currants, '\n",
            " 'and a hone-vinegar and lemon dressing. Easy, right? And good for winter. And '\n",
            " \"not what you'd expect from this book.\\n\"\n",
            " '\\n'\n",
            " 'Some of the techniques that will likely change your own regular practices '\n",
            " 'include \"low-temp oven steak,\" which involves first freezing steaks or any '\n",
            " 'other tender cut of meat, quickly searing them, then putting it into the '\n",
            " 'oven at the lowest temperature until a digital thermometer reads 133 F (or '\n",
            " 'your desired degree of doneness). This, Myhrvold explains, yields meat '\n",
            " \"that's evenly done to exactly the degree you want, rather than meat with an \"\n",
            " 'overdone exterior and underdone dead-center.\\n'\n",
            " '\\n'\n",
            " 'And there are unexpected forays, such as deconstructed carnitas that just '\n",
            " 'require a pressure cooker and provide incidental lessons in braising meat, '\n",
            " 'which the authors extend on the next pages to other braised recipes: steamed '\n",
            " 'omelets that, like the frozen-then-low-temp steak, result in a completely '\n",
            " 'uniform doneness and texture that the authors assure us is tender and '\n",
            " 'delicate, as well as braised short ribs that, of course, require a sous-vide '\n",
            " 'setup, the $300-or-so vacuum-bag and controlled water-bath machine that '\n",
            " 'started being a foodie must last year--and a set-up, on a larger scale, that '\n",
            " 'most restaurant cooks routinely use for short ribs, though they almost '\n",
            " 'always fail to say so.\\n'\n",
            " '\\n'\n",
            " \"I still think you should go into debt to get the six-volume set--but that's \"\n",
            " 'just for hardcore cooks who want an invaluable reference. This is the book '\n",
            " 'for anyone who wants to understand her or his kitchen better, and have a '\n",
            " 'taste of what all the controversy over sous-vide and xanthan gum has been '\n",
            " 'about.\\n'\n",
            " '\\n'\n",
            " 'Burma: Rivers of Flavor, by Naomi Duguid\\n'\n",
            " '\\n'\n",
            " 'Naomi Duguid, a tireless wanderer, a photographer with marvelous eye, and a '\n",
            " 'teacher of cooking classes in Chiang Mai, Thailand, has a deep knowledge of '\n",
            " 'Asia from her decades of chronicling and writing about village food in books '\n",
            " 'like Hot Sour Salty Sweet and Seductions of Rice. She traveled all over '\n",
            " 'Burma when the kind of cultural opening we saw this year was still a dream, '\n",
            " 'and by good fortune the release of Burma: Rivers of Flavor coincided with '\n",
            " \"President Obama's November visit.\\n\"\n",
            " '\\n'\n",
            " 'She found a cuisine related to the Thai food she knows so well--chiles, '\n",
            " 'ginger, lemon grass, turmeric, fish sauce, tomatoes as a condiment--but '\n",
            " 'different in some of its building blocks, like shallot oil, fried garlic, '\n",
            " 'chile oil, and, for protein, toasted chickpea flour and pan-roasted peanuts. '\n",
            " 'Once you have a few of these on hand, you can make easy dishes like golden '\n",
            " 'egg curry, the boiled eggs quickly deep-fried to give them a sizzling crust, '\n",
            " 'and put in a fresh tomato-chile sauce with fresh sliced cayenne chiles, or '\n",
            " 'an easy stir-fry of pork tenderloin with star anise and palm sugar water. '\n",
            " 'And as usual, Duguid has new ways to make rice, like jasmine rice with '\n",
            " 'shallots, cinnamon stick, turmeric, and coconut milk, which sounds '\n",
            " 'celebratory. The real influence the book is likely to have on your cooking, '\n",
            " 'though, are the salads and soups--what sound to be the real glory of Burmese '\n",
            " 'food--easily assembled from various vegetables and leftover meats dressed '\n",
            " 'with lime juice, shallot oil, and various fresh herbs that give them new '\n",
            " 'life.\\n'\n",
            " '\\n'\n",
            " 'From A Polish Country House Kitchen: 90 Recipes for the Ultimate Comfort '\n",
            " 'Food, by Anne Applebaum & Danielle Crittenden')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prAOShhQwSpq",
        "outputId": "c6927342-cd5d-4ef0-eb1d-ff58832efee9"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text'],\n",
              "    num_rows: 8013769\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 - Inspect training metrics and perform abbreviated evaluation"
      ],
      "metadata": {
        "id": "AXXqSB1H7TVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_args = {\n",
        "    # - [ ] TODO: Figure out what evaluation arguments are needed...\n",
        "}\n",
        "evaluate(model, test_data, **eval_args)"
      ],
      "metadata": {
        "id": "3otNK95_7Xq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. `Implementation` - Mechanistic Interpretability Analysis"
      ],
      "metadata": {
        "id": "EzyPR6QrV-U4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 - Using the Autoencoder\n"
      ],
      "metadata": {
        "id": "4OM8HO6OWH7Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_ = get_recons_loss(num_batches=5, local_encoder=encoder)"
      ],
      "metadata": {
        "id": "2SXB4-mdWK60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yvxiv_DKWLeB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 - Rare Features Are All The Same"
      ],
      "metadata": {
        "id": "x9Iok8SZB4fg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each feature we can get the frequency at which it's non-zero (per token, averaged across a bunch of batches), and plot a histogram"
      ],
      "metadata": {
        "id": "skvpaPClM7Nb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freqs = get_freqs(num_batches = 50, local_encoder = encoder)"
      ],
      "metadata": {
        "id": "5SECGnWLNAlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add 1e-6.5 so that dead features show up as log_freq -6.5\n",
        "log_freq = (freqs + 10**-6.5).log10()\n",
        "px.histogram(utils.to_numpy(log_freq), title=\"Log Frequency of Features\", histnorm='percent')"
      ],
      "metadata": {
        "id": "_Zn7g7WgNTQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that it's clearly bimodal! Let's define rare features as those with freq < 1e-4, and look at the cosine sim of each feature with the average rare feature - we see that almost all rare features correspond to this feature!"
      ],
      "metadata": {
        "id": "c612eWjYNpdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "is_rare = freqs < 1e-4\n",
        "rare_enc = encoder.W_enc[:, is_rare]\n",
        "rare_mean = rare_enc.mean(-1)\n",
        "px.histogram(utils.to_numpy(rare_mean @ encoder.W_enc / rare_mean.norm() / encoder.W_enc.norm(dim=0)), title=\"Cosine Sim with Ave Rare Feature\", color=utils.to_numpy(is_rare), labels={\"color\": \"is_rare\", \"count\": \"percent\", \"value\": \"cosine_sim\"}, marginal=\"box\", histnorm=\"percent\", barmode='overlay')"
      ],
      "metadata": {
        "id": "GbM9UZsJN0Uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 - Interpreting A Feature"
      ],
      "metadata": {
        "id": "eZCqUIB9Bzx_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's go and investigate a non rare feature, feature 7"
      ],
      "metadata": {
        "id": "3m_u8-zXRW2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_id = 7 # @param {type:\"number\"}\n",
        "batch_size = 128 # @param {type:\"number\"}\n",
        "\n",
        "print(f\"Feature freq: {freqs[7].item():.4f}\")"
      ],
      "metadata": {
        "id": "_HrsTqVIUKC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run the model on some text and then use the autoencoder to process the MLP activations"
      ],
      "metadata": {
        "id": "AYoGLyl2VpA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = all_tokens[:batch_size]\n",
        "_, cache = model.run_with_cache(tokens, stop_at_layer=1, names_filter=utils.get_act_name(\"post\", 0))\n",
        "mlp_acts = cache[utils.get_act_name(\"post\", 0)]\n",
        "mlp_acts_flattened = mlp_acts.reshape(-1, cfg[\"d_mlp\"])\n",
        "loss, x_reconstruct, hidden_acts, l2_loss, l1_loss = encoder(mlp_acts_flattened)\n",
        "# This is equivalent to:\n",
        "# hidden_acts = F.relu((mlp_acts_flattened - encoder.b_dec) @ encoder.W_enc + encoder.b_enc)\n",
        "print(\"hidden_acts.shape\", hidden_acts.shape)"
      ],
      "metadata": {
        "id": "TBKY9P_PULJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now sort and display the top tokens, and we see that this feature activates on text like \" and I\" (ditto for other connectives and pronouns)! It seems interpretable!\n",
        "\n",
        "**Aside:** Note on how to read the context column:\n",
        "\n",
        "A line like \"·himself·as·democratic·socialist·and|·he|·favors\" means that the preceding 5 tokens are \" himself as democratic socialist and\", the current token is \" he\" and the next token is \" favors\".  · are spaces, ↩ is a newline.\n",
        "\n",
        "This gets a bit confusing for this feature, since the pipe separators look a lot like a capital I\n"
      ],
      "metadata": {
        "id": "D0-vxYAIVtxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_df = make_token_df(tokens)\n",
        "token_df[\"feature\"] = utils.to_numpy(hidden_acts[:, feature_id])\n",
        "token_df.sort_values(\"feature\", ascending=False).head(20).style.background_gradient(\"coolwarm\")"
      ],
      "metadata": {
        "id": "6LQet6vaU60H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's easy to misread evidence like the above, so it's useful to take some text and edit it and see how this changes the model's activations. Here's a hacky interactive tool to play around with some text."
      ],
      "metadata": {
        "id": "H_SsYbIhWm43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.cfg"
      ],
      "metadata": {
        "id": "xHWCNBe81qAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"The 1899 Kentucky gubernatorial election was held on November 7, 1899. The Republican incumbent, William Bradley, was term-limited. The Democrats chose William Goebel. Republicans nominated William Taylor. Taylor won by a vote of 193,714 to 191,331. The vote was challenged on grounds of voter fraud, but the Board of Elections, though stocked with pro-Goebel members, certified the result. Democratic legislators began investigations, but before their committee could report, Goebel was shot by an unknown assassin (event pictured) on January 30, 1900. Democrats voided enough votes to swing the election to Goebel, Taylor was deposed, and Goebel was sworn into office on January 31. He died on February 3. The lieutenant governor of Kentucky, J. C. W. Beckham, became governor, and battled Taylor in court. Beckham won on appeal, and Taylor fled to Indiana, fearing arrest as an accomplice. The only persons convicted in connection with the killing were later pardoned; the assassin's identity remains a mystery\"\n",
        "t = model.to_tokens(s)\n",
        "print(t)"
      ],
      "metadata": {
        "id": "wx6MkfEk0osY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "starting_text = \"Hero and I will head to Samantha and Mark's, then he and she will. Then I or you\" # @param {type:\"string\"}\n",
        "make_feature_vis_gradio(feature_id, starting_text)"
      ],
      "metadata": {
        "id": "HbgjmwTnQman"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. `Conjecture` - Connections with Supersymmetry"
      ],
      "metadata": {
        "id": "vxzEg4XchFe9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 - Notation"
      ],
      "metadata": {
        "id": "_mhMjXIZw3Dk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d1qM2PckhMXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 - Motivation"
      ],
      "metadata": {
        "id": "6Kow525Uw57l"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Ni57IZlw_Ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Formalism"
      ],
      "metadata": {
        "id": "u_mCqkVVxBsw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m2T4BRqoxFDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. `Conjecture` - Next Steps"
      ],
      "metadata": {
        "id": "Y8o7zwIHxQUw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HuxzKQeexRrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. References"
      ],
      "metadata": {
        "id": "L759zICsht0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NZaMtzWhhw_B"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c54f40b367843b7b3909d6df28b33f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d85218137d254d49ad331e4be9af7dae",
              "IPY_MODEL_3526fc44f5a9427bb14161b5c87b0c18",
              "IPY_MODEL_be89efd8698a4560834211e728aaf759"
            ],
            "layout": "IPY_MODEL_521bdaf10a39426e90dba01d9b70287c"
          }
        },
        "d85218137d254d49ad331e4be9af7dae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bc5f4eafca84d9cadbdb439f60ff2a8",
            "placeholder": "​",
            "style": "IPY_MODEL_f90cbcfbbee846d2948d7f1ab5bab1b7",
            "value": "Running training loop...:   0%"
          }
        },
        "3526fc44f5a9427bb14161b5c87b0c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d44053627f0945d5957117fa6dfd18ca",
            "max": 8013769,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_816c5324c9244d96a215635e0abe82b1",
            "value": 1000
          }
        },
        "be89efd8698a4560834211e728aaf759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4688f6948e1e485185f9d1c3569019b8",
            "placeholder": "​",
            "style": "IPY_MODEL_e943203383134a209c38227748aff16a",
            "value": " 1000/8013769 [00:00&lt;43:09, 3093.98it/s]"
          }
        },
        "521bdaf10a39426e90dba01d9b70287c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bc5f4eafca84d9cadbdb439f60ff2a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f90cbcfbbee846d2948d7f1ab5bab1b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d44053627f0945d5957117fa6dfd18ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "816c5324c9244d96a215635e0abe82b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4688f6948e1e485185f9d1c3569019b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e943203383134a209c38227748aff16a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}